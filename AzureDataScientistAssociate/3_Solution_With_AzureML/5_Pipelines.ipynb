{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Orchestrate machine learning with pipelines\n",
    "\n",
    "Experiment that we define with Scriptconfig contains every step of a machine learning pipeline which sometimes it is better to split and to be run on one or more compute targets, especially for enterprise solutions. Pipelines are key to implementing MLOps solution in Azure.\n",
    "\n",
    "In Azure Machine Learning, a pipeline is a workflow of machine learning tasks in which each task is implemented as a step.\n",
    "\n",
    "It allow us to arrange sequentially or in parallel some tasks and to decide which compute target should run that step.\n",
    "\n",
    "A pipeline can be executed as an experiment.\n",
    "\n",
    "There are multiple steps for the pipeline, such as the following ones:\n",
    "- PythonScriptStep: runs a python script.\n",
    "- DataTransferStep: uses Azure Data Factory to copy data between data stores.\n",
    "- DatabricksStep: runs a notebook, script, or compiled JAR on a databricks cluster.\n",
    "- AdlaStep: Runs a U-SQL job in Azure Data Lake Analytics.\n",
    "- ParallelRunStep - Runs a Python script as a distributed task on multiple compute nodes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define a pipeline\n",
    "\n",
    "First of all, the steps must be defined.\n",
    "\n",
    "```\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Step to run a Python script\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster')\n",
    "\n",
    "# Step to train a model\n",
    "step2 = PythonScriptStep(name = 'train model',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'train_model.py',\n",
    "                         compute_target = 'aml-cluster')\n",
    "```\n",
    "\n",
    "Then, an experiment is initiated which will manage the pipeline defined by the previous steps.\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Construct the pipeline\n",
    "train_pipeline = Pipeline(workspace = ws, steps = [step1,step2])\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
    "pipeline_run = experiment.submit(train_pipeline)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manage results between steps\n",
    "\n",
    "In the middle, OutputFileDatasetConfig object are used to deliver intermediary data between steps in the pipeline. It's a special kind of data that references a location in a datastore.\n",
    "\n",
    "```\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "\n",
    "# Get a dataset for the initial data\n",
    "raw_ds = Dataset.get_by_name(ws, 'raw_dataset')\n",
    "\n",
    "# Define a PipelineData object to pass data between steps\n",
    "data_store = ws.get_default_datastore()\n",
    "prepped_data = OutputFileDatasetConfig('prepped')\n",
    "\n",
    "# Step to run a Python script\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         # Script arguments include PipelineData\n",
    "                         arguments = ['--raw-ds', raw_ds.as_named_input('raw_data'),\n",
    "                                      '--out_folder', prepped_data])\n",
    "\n",
    "# Step to run an estimator\n",
    "step2 = PythonScriptStep(name = 'train model',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'train_model.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         # Pass as script argument\n",
    "                         arguments=['--training-data', prepped_data.as_input()])\n",
    "```\n",
    "In the Python Script File step:\n",
    "```\n",
    "# code in data_prep.py\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raw-ds', type=str, dest='raw_dataset_id')\n",
    "parser.add_argument('--out_folder', type=str, dest='folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.folder\n",
    "\n",
    "# Get input dataset as dataframe\n",
    "raw_df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# code to prep data (in this case, just select specific columns)\n",
    "prepped_df = raw_df[['col1', 'col2', 'col3']]\n",
    "\n",
    "# Save prepped data to the PipelineData location\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, 'prepped_data.csv')\n",
    "prepped_df.to_csv(output_path)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reuse option\n",
    "\n",
    "Sometimes, pipelines can take too much time. So, to reduce the computstional time, it's possible to reuse the results of the step in which the code didn't change. This can save a lot of time but on the other hand, results can be a little stale if the input data changed. allow_reuse  is the parameter which enables this behaviour for the chosen step.\n",
    "\n",
    "```\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         runconfig = run_config,\n",
    "                         inputs=[raw_ds.as_named_input('raw_data')],\n",
    "                         outputs=[prepped_data],\n",
    "                         arguments = ['--folder', prepped_data]),\n",
    "                         # Disable step reuse\n",
    "                         allow_reuse = False)\n",
    "```\n",
    "\n",
    "Otherwise, you can force all the pipeline steps to run::\n",
    "\n",
    "```\n",
    "pipeline_run = experiment.submit(train_pipeline, regenerate_outputs=True)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publish\n",
    "\n",
    "A REST endpoint can be created in order to deploy the pipeline.\n",
    "\n",
    "```\n",
    "published_pipeline = pipeline.publish(name='training_pipeline',\n",
    "                                          description='Model training pipeline',\n",
    "                                          version='1.0')\n",
    "```\n",
    "\n",
    "Or you can select one pipeline among the ones which run in the experiment:\n",
    "\n",
    "```\n",
    "# Get the most recent run of the pipeline\n",
    "pipeline_experiment = ws.experiments.get('training-pipeline')\n",
    "run = list(pipeline_experiment.get_runs())[0]\n",
    "\n",
    "# Publish the pipeline from the run\n",
    "published_pipeline = run.publish_pipeline(name='training_pipeline',\n",
    "                                          description='Model training pipeline',\n",
    "                                          version='1.0')\n",
    "```\n",
    "You can also define its URI:\n",
    "```\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (546770834.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\ravazzil\\AppData\\Local\\Temp\\ipykernel_1148\\546770834.py\"\u001B[1;36m, line \u001B[1;32m3\u001B[0m\n\u001B[1;33m    A REST endpoint can be created in order to deploy the pipeline.\u001B[0m\n\u001B[1;37m         ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "To initiate a published endpoint, you make an HTTP request to its REST endpoint, passing an authorization header with a token for a service principal with permission to run the pipeline, and a JSON payload specifying the experiment name. The pipeline is run asynchronously, so the response from a successful REST call includes the run ID. You can use the run ID to track the run in Azure Machine Learning studio.\n",
    "\n",
    "For example, the following Python code makes a REST request to run a pipeline and displays the returned run ID.\n",
    "\n",
    "```\n",
    "import requests\n",
    "\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={\"ExperimentName\": \"run_training_pipeline\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "print(run_id)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use pipeline parameters\n",
    "\n",
    "PipelineParameter allows you to define global value for the pipeline.\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "reg_param = PipelineParameter(name='reg_rate', default_value=0.01)\n",
    "\n",
    "...\n",
    "\n",
    "step2 = PythonScriptStep(name = 'train model',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'train_model.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         # Pass parameter as script argument\n",
    "                         arguments=['--in_folder', prepped_data,\n",
    "                                    '--reg', reg_param],\n",
    "                         inputs=[prepped_data])\n",
    "```\n",
    "\n",
    "In this way, the pipeline is parameterized and you can pass parameter values in the JSON payload for the REST interface, like this one:\n",
    "\n",
    "```\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={\"ExperimentName\": \"run_training_pipeline\",\n",
    "                               \"ParameterAssignments\": {\"reg_rate\": 0.1}})\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Schedule pipelines\n",
    "\n",
    "After the pipeline has been published, schedule it like this:\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "daily = ScheduleRecurrence(frequency='Day', interval=1)\n",
    "pipeline_schedule = Schedule.create(ws, name='Daily Training',\n",
    "                                        description='trains model every day',\n",
    "                                        pipeline_id=published_pipeline.id,\n",
    "                                        experiment_name='Training_Pipeline',\n",
    "                                        recurrence=daily)\n",
    "```\n",
    "\n",
    "To schedule a pipeline to run whenever data changes, you must create a Schedule that monitors a specified path on a datastore, like this:\n",
    "\n",
    "```\n",
    "from azureml.core import Datastore\n",
    "from azureml.pipeline.core import Schedule\n",
    "\n",
    "training_datastore = Datastore(workspace=ws, name='blob_data')\n",
    "pipeline_schedule = Schedule.create(ws, name='Reactive Training',\n",
    "                                    description='trains model on data change',\n",
    "                                    pipeline_id=published_pipeline.id,\n",
    "                                    experiment_name='Training_Pipeline',\n",
    "                                    datastore=training_datastore,\n",
    "                                    path_on_datastore='data/training')\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.get(workspace = ws, name = 'training_environment')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "pipeline_cluster = ComputeTarget(workspace=ws, name='aml-cluster')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "pipeline_run_config.environment = env"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = 'Script',\n",
    "                                script_name = \"7_Pipeline_I.py\",\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = 'Script',\n",
    "                                script_name = \"8_Pipeline_II.py\",\n",
    "                                arguments = ['--training-data', prepped_data.as_input()],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Prepare Data [2c075aca][02126d70-004f-4201-a0eb-b541915c35e7], (This step will run and generate new outputs)\n",
      "Created step Train and Register Model [51ad56d2][a27e4535-0133-42f5-b11b-483996e556dd], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun ac71d0f5-63d0-4ac7-89cf-63a0caa955fb\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ac71d0f5-63d0-4ac7-89cf-63a0caa955fb?wsid=/subscriptions/d12c1b85-0a70-4232-b483-12d1ffcfc148/resourcegroups/ResourceGroupRavazzi/workspaces/ravazzil-workspace&tid=b00367e2-193a-4f48-94de-7245d45c0947\n",
      "PipelineRunId: ac71d0f5-63d0-4ac7-89cf-63a0caa955fb\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ac71d0f5-63d0-4ac7-89cf-63a0caa955fb?wsid=/subscriptions/d12c1b85-0a70-4232-b483-12d1ffcfc148/resourcegroups/ResourceGroupRavazzi/workspaces/ravazzil-workspace&tid=b00367e2-193a-4f48-94de-7245d45c0947\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: ffb874b6-2043-4151-9c6e-960dc7846bb2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ffb874b6-2043-4151-9c6e-960dc7846bb2?wsid=/subscriptions/d12c1b85-0a70-4232-b483-12d1ffcfc148/resourcegroups/ResourceGroupRavazzi/workspaces/ravazzil-workspace&tid=b00367e2-193a-4f48-94de-7245d45c0947\n",
      "StepRun( Prepare Data ) Status: NotStarted\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2023/01/01 21:18:34 Downloading source code...\n",
      "2023/01/01 21:18:35 Finished downloading source code\n",
      "2023/01/01 21:18:35 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2023/01/01 21:18:35 Successfully set up Docker network: acb_default_network\n",
      "2023/01/01 21:18:35 Setting up Docker configuration...\n",
      "2023/01/01 21:18:36 Successfully set up Docker configuration\n",
      "2023/01/01 21:18:36 Logging in to registry: 0ee9671f71444125a665a1b9cffe5395.azurecr.io\n",
      "2023/01/01 21:18:37 Successfully logged into 0ee9671f71444125a665a1b9cffe5395.azurecr.io\n",
      "2023/01/01 21:18:37 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/01/01 21:18:37 Scanning for dependencies...\n",
      "2023/01/01 21:18:37 Successfully scanned dependencies\n",
      "2023/01/01 21:18:37 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  71.68kB\n",
      "\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
      "Digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1@sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      " ---> b6fd6a8d28e9\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 6e417d015989\n",
      "Removing intermediate container 6e417d015989\n",
      " ---> ca4a1851efdd\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 17e90fd46a5c\n",
      "Removing intermediate container 17e90fd46a5c\n",
      " ---> cc8b2a611a71\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in 51161c63bc08\n",
      "Removing intermediate container 51161c63bc08\n",
      " ---> 6ca856617407\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 2cd7d1fc2727\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in b88ab08367d9\n",
      "Removing intermediate container b88ab08367d9\n",
      " ---> 9a03e6ab9323\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 3693304abba2\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 2c7f079a3dee\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2022.6.15    | 156 KB    |            |   0% \n",
      "certifi-2022.6.15    | 156 KB    | ########## | 100% \n",
      "certifi-2022.6.15    | 156 KB    | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "ca-certificates-2022 | 131 KB    |            |   0% \n",
      "ca-certificates-2022 | 131 KB    | ########## | 100% \n",
      "\n",
      "setuptools-61.2.0    | 1.3 MB    |            |   0% \n",
      "setuptools-61.2.0    | 1.3 MB    | ########## | 100% \n",
      "setuptools-61.2.0    | 1.3 MB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    |            |   0% \n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    |            |   0% \n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \n",
      "\n",
      "pip-22.1.2           | 2.9 MB    |            |   0% \n",
      "pip-22.1.2           | 2.9 MB    | ########## | 100% \n",
      "pip-22.1.2           | 2.9 MB    | ########## | 100% \n",
      "\n",
      "libgomp-11.2.0       | 560 KB    |            |   0% \n",
      "libgomp-11.2.0       | 560 KB    | ########## | 100% \n",
      "libgomp-11.2.0       | 560 KB    | ########## | 100% \n",
      "\n",
      "readline-8.1.2       | 423 KB    |            |   0% \n",
      "readline-8.1.2       | 423 KB    | ########## | 100% \n",
      "readline-8.1.2       | 423 KB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.12          | 130 KB    |            |   0% \n",
      "zlib-1.2.12          | 130 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.3          | 1.1 MB    |            |   0% \n",
      "ncurses-6.3          | 1.1 MB    | ########## | 100% \n",
      "ncurses-6.3          | 1.1 MB    | ########## | 100% \n",
      "\n",
      "ld_impl_linux-64-2.3 | 732 KB    |            |   0% \n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \n",
      "\n",
      "libffi-3.3           | 54 KB     |            |   0% \n",
      "libffi-3.3           | 54 KB     | ########## | 100% \n",
      "\n",
      "_openmp_mutex-5.1    | 20 KB     |            |   0% \n",
      "_openmp_mutex-5.1    | 20 KB     | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 389 KB    |            |   0% \n",
      "xz-5.2.5             | 389 KB    | ########## | 100% \n",
      "\n",
      "sqlite-3.39.2        | 1.5 MB    |            |   0% \n",
      "sqlite-3.39.2        | 1.5 MB    | ########## | 100% \n",
      "sqlite-3.39.2        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "python-3.8.13        | 22.7 MB   |            |   0% \n",
      "python-3.8.13        | 22.7 MB   | ######5    |  66% \n",
      "python-3.8.13        | 22.7 MB   | ########## | 100% \n",
      "\n",
      "wheel-0.37.1         | 31 KB     |            |   0% \n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \n",
      "\n",
      "openssl-1.1.1q       | 3.8 MB    |            |   0% \n",
      "openssl-1.1.1q       | 3.8 MB    | ########## | 100% \n",
      "openssl-1.1.1q       | 3.8 MB    | ########## | 100% \n",
      "\n",
      "tk-8.6.12            | 3.3 MB    |            |   0% \n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv._yyi8wkn.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.48.0-py3-none-any.whl (2.0 kB)\n",
      "Collecting azureml-core~=1.48.0\n",
      "  Downloading azureml_core-1.48.0-py3-none-any.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 49.9 MB/s eta 0:00:00\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.48.0\n",
      "  Downloading azureml_dataset_runtime-1.48.0-py3-none-any.whl (2.2 kB)\n",
      "Collecting azureml-inference-server-http~=0.7.2\n",
      "  Downloading azureml_inference_server_http-0.7.7-py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 10.4 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-resource<22.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-21.2.1-py3-none-any.whl (2.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 131.3 MB/s eta 0:00:00\n",
      "Collecting pyopenssl<23.0.0\n",
      "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 13.7 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-10.1.0-py3-none-any.whl (605 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 605.9/605.9 kB 93.8 MB/s eta 0:00:00\n",
      "Collecting azure-core<2.0.0\n",
      "  Downloading azure_core-1.26.1-py3-none-any.whl (172 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 172.6/172.6 kB 45.7 MB/s eta 0:00:00\n",
      "Collecting knack~=0.10.0\n",
      "  Downloading knack-0.10.1-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.1/61.1 kB 16.8 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.9.2-py3-none-any.whl (26 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.20.0-py2.py3-none-any.whl (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.0/90.0 kB 25.0 MB/s eta 0:00:00\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting urllib3<2.0.0,>=1.23\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.6/140.6 kB 34.9 MB/s eta 0:00:00\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2022.7-py2.py3-none-any.whl (499 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 499.4/499.4 kB 84.9 MB/s eta 0:00:00\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.1/213.1 kB 44.3 MB/s eta 0:00:00\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 9.4 MB/s eta 0:00:00\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━���━━━━━━━━ 62.8/62.8 kB 14.0 MB/s eta 0:00:00\n",
      "Collecting docker<7.0.0\n",
      "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.5/147.5 kB 34.1 MB/s eta 0:00:00\n",
      "Collecting packaging<22.0,>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.5/55.5 kB 13.9 MB/s eta 0:00:00\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.10.3-py3-none-any.whl (29 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 49.5 MB/s eta 0:00:00\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 114.3 MB/s eta 0:00:00\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41\n",
      "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 102.9 MB/s eta 0:00:00\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 22.0 MB/s eta 0:00:00\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.4/141.4 kB 36.8 MB/s eta 0:00:00\n",
      "Collecting msrest<=0.7.1,>=0.5.1\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 22.3 MB/s eta 0:00:00\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting argcomplete<3\n",
      "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting azure-mgmt-storage<21.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 139.3 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-authorization<4,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-3.0.0-py3-none-any.whl (965 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 965.9/965.9 kB 118.2 MB/s eta 0:00:00\n",
      "Collecting azureml-dataprep<4.9.0a,>=4.8.0a\n",
      "  Downloading azureml_dataprep-4.8.3-py3-none-any.whl (43.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 MB 38.2 MB/s eta 0:00:00\n",
      "Collecting numpy!=1.19.3\n",
      "  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━���━━━━ 17.3/17.3 MB 107.2 MB/s eta 0:00:00\n",
      "Collecting pyarrow<=9.0.0,>=0.17.0\n",
      "  Downloading pyarrow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 35.3/35.3 MB 89.1 MB/s eta 0:00:00\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting inference-schema~=1.5.0\n",
      "  Downloading inference_schema-1.5-py3-none-any.whl (21 kB)\n",
      "Collecting flask-cors~=3.0.1\n",
      "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 18.4 MB/s eta 0:00:00\n",
      "Collecting opencensus-ext-azure~=1.1.0\n",
      "  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.8/42.8 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/python3.8/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults->-r /azureml-environment-setup/condaenv._yyi8wkn.requirements.txt (line 1)) (61.2.0)\n",
      "Collecting typing-extensions>=4.0.1\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting six>=1.11.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.3.2\n",
      "  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 21.8 MB/s eta 0:00:00\n",
      "Collecting dotnetcore2<4.0.0,>=3.0.0\n",
      "  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.1/31.1 MB 55.4 MB/s eta 0:00:00\n",
      "Collecting azureml-dataprep-rslex~=2.15.0dev0\n",
      "  Downloading azureml_dataprep_rslex-2.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 116.9 MB/s eta 0:00:00\n",
      "Collecting azure-identity==1.7.0\n",
      "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.1/129.1 kB 28.2 MB/s eta 0:00:00\n",
      "Collecting pyyaml<7.0.0,>=5.1.0\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 94.0 MB/s eta 0:00:00\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp38-cp38-manylinux1_x86_64.whl (1.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 121.9 MB/s eta 0:00:00\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.7/442.7 kB 71.9 MB/s eta 0:00:00\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━���━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.3/55.3 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting Flask>=0.9\n",
      "  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 24.2 MB/s eta 0:00:00\n",
      "Collecting wrapt<=1.12.1,>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 118.8 MB/s eta 0:00:00\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting portalocker<3,>=1.0\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib/python3.8/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.48.0->azureml-defaults->-r /azureml-environment-setup/condaenv._yyi8wkn.requirements.txt (line 1)) (2022.6.15)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 17.7 MB/s eta 0:00:00\n",
      "Collecting opencensus<1.0.0,>=0.11.0\n",
      "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 21.1 MB/s eta 0:00:00\n",
      "Collecting psutil>=5.6.3\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.2/280.2 kB 51.5 MB/s eta 0:00:00\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 23.5 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 593.7/593.7 kB 83.4 MB/s eta 0:00:00\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 95.2 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 15.0 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.4/48.4 kB 10.2 MB/s eta 0:00:00\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━���━━━━━━━━━━━━━━━━━━ 118.7/118.7 kB 31.8 MB/s eta 0:00:00\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 26.1 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=3.6.0\n",
      "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 26.0 MB/s eta 0:00:00\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 kB 44.9 MB/s eta 0:00:00\n",
      "Collecting opencensus-context>=0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 120.3/120.3 kB 22.4 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 36.3 MB/s eta 0:00:00\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 10.3 MB/s eta 0:00:00\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 14.0 MB/s eta 0:00:00\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.0/218.0 kB 45.6 MB/s eta 0:00:00\n",
      "Collecting google-auth<3.0dev,>=2.14.1\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.0/177.0 kB 36.1 MB/s eta 0:00:00\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
      "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 67.6 MB/s eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 26.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: fusepy, wrapt\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=908fd4a45ad6caaaafa8e1f0ae61525da1ecbe05a212b87b2715919b7e810a0d\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/41/10/f70b83a1164fdb95e7bc37bace13114a024227e56c2fee02bb\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=81713 sha256=0658a4e9f5e0dd0225fa570aeb4bc200b36f42a6ebad4958166548e8c5ba930d\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built fusepy wrapt\n",
      "Installing collected packages: wrapt, pytz, pyasn1, opencensus-context, fusepy, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, zipp, websocket-client, urllib3, typing-extensions, tabulate, six, rsa, pyyaml, PySocks, pyrsistent, pyparsing, PyJWT, pygments, pycparser, pyasn1-modules, psutil, protobuf, portalocker, pkgutil-resolve-name, pkginfo, pathspec, oauthlib, numpy, MarkupSafe, jsonpickle, jmespath, jeepney, itsdangerous, idna, humanfriendly, gunicorn, distro, contextlib2, cloudpickle, click, charset-normalizer, cachetools, bcrypt, backports.tempfile, attrs, argcomplete, Werkzeug, requests, python-dateutil, pyarrow, packaging, knack, Jinja2, isodate, importlib-resources, importlib-metadata, googleapis-common-protos, google-auth, dotnetcore2, cffi, requests-oauthlib, pynacl, jsonschema, inference-schema, google-api-core, Flask, docker, cryptography, azure-core, SecretStorage, pyopenssl, paramiko, opencensus, msrest, flask-cors, azure-mgmt-core, adal, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, msal-extensions, azure-graphrbac, azureml-core, azure-identity, opencensus-ext-azure, azureml-dataprep, azureml-inference-server-http, azureml-dataset-runtime, azureml-defaults\n",
      "Successfully installed Flask-2.2.2 Jinja2-3.1.2 MarkupSafe-2.1.1 PyJWT-2.6.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.2.2 adal-1.2.7 argcomplete-2.0.0 attrs-22.2.0 azure-common-1.1.28 azure-core-1.26.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-3.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.1.0 azure-mgmt-resource-21.2.1 azure-mgmt-storage-20.1.0 azureml-core-1.48.0 azureml-dataprep-4.8.3 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.15.1 azureml-dataset-runtime-1.48.0 azureml-defaults-1.48.0 azureml-inference-server-http-0.7.7 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-5.2.0 cffi-1.15.1 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 contextlib2-21.6.0 cryptography-38.0.4 distro-1.8.0 docker-6.0.1 dotnetcore2-3.1.23 flask-cors-3.0.10 fusepy-3.0.1 google-api-core-2.11.0 google-auth-2.15.0 googleapis-common-protos-1.57.0 gunicorn-20.1.0 humanfriendly-10.0 idna-3.4 importlib-metadata-6.0.0 importlib-resources-5.10.2 inference-schema-1.5 isodate-0.6.1 itsdangerous-2.1.2 jeepney-0.8.0 jmespath-1.0.1 jsonpickle-2.2.0 jsonschema-4.17.3 knack-0.10.1 msal-1.20.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.24.1 oauthlib-3.2.2 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 packaging-21.3 paramiko-2.12.0 pathspec-0.10.3 pkginfo-1.9.2 pkgutil-resolve-name-1.3.10 portalocker-2.6.0 protobuf-4.21.12 psutil-5.9.4 pyarrow-9.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.14.0 pynacl-1.5.0 pyopenssl-22.1.0 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 pytz-2022.7 pyyaml-6.0 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 tabulate-0.9.0 typing-extensions-4.4.0 urllib3-1.26.13 websocket-client-1.4.2 wrapt-1.12.1 zipp-3.11.0\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001B[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 22.11.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001B[0mWARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 2c7f079a3dee\n",
      " ---> f71c475d04d1\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/bin:$PATH\n",
      " ---> Running in 10dd1efa364b\n",
      "Removing intermediate container 10dd1efa364b\n",
      " ---> 70d0a2aa3c98\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 1fbc1f8bfd3e\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in 9210e2943465\n",
      "Copying environment context\n",
      "Removing intermediate container 9210e2943465\n",
      " ---> 58d0fa3c6461\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 70de27368a58\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3\n",
      " ---> Running in 98b779870053\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 98b779870053\n",
      " ---> 7913a115f1a4\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3\n",
      " ---> Running in e8404146fa45\n",
      "Removing intermediate container e8404146fa45\n",
      " ---> 4df1ab86dd7f\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 2981cbd2a29e\n",
      "Removing intermediate container 2981cbd2a29e\n",
      " ---> e6a121156a4e\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_f3f7e6c5fb83d94df23933000bf02da3 CONDA_PREFIX=/azureml-envs/azureml_f3f7e6c5fb83d94df23933000bf02da3\n",
      " ---> Running in d2af84e8c108\n",
      "Removing intermediate container d2af84e8c108\n",
      " ---> 124ca183f2c0\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> d27633619dfd\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in f5a61c1d71d9\n",
      "Removing intermediate container f5a61c1d71d9\n",
      " ---> 1e7d0df7f131\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in c6d4700d772c\n",
      "Removing intermediate container c6d4700d772c\n",
      " ---> bed01caa1086\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 5322f5bf662e\n",
      "Removing intermediate container 5322f5bf662e\n",
      " ---> 906138351fbf\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in a6a57ddb3e5c\n",
      "Removing intermediate container a6a57ddb3e5c\n",
      " ---> 294aa5a2c788\n",
      "Successfully built 294aa5a2c788\n",
      "Successfully tagged 0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f:latest\n",
      "Successfully tagged 0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f:1\n",
      "2023/01/01 21:21:12 Successfully executed container: acb_step_0\n",
      "2023/01/01 21:21:12 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/01/01 21:21:12 Pushing image: 0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f:1, attempt 1\n",
      "The push refers to repository [0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f]\n",
      "7379bcdcda5f: Preparing\n",
      "66cd0085c1ee: Preparing\n",
      "100c5dee2eae: Preparing\n",
      "e296e18ea079: Preparing\n",
      "310a7e118b6f: Preparing\n",
      "feea62d2284a: Preparing\n",
      "b935f2592798: Preparing\n",
      "002d32ec2908: Preparing\n",
      "0de849f8e565: Preparing\n",
      "c51f799dca8f: Preparing\n",
      "2bcdf82aed44: Preparing\n",
      "b21e039321ee: Preparing\n",
      "445a2d2462f0: Preparing\n",
      "6e539e6b11c3: Preparing\n",
      "b67f8b8feccd: Preparing\n",
      "7e60813e02c4: Preparing\n",
      "0d66ccba1288: Preparing\n",
      "20b46ade1e43: Preparing\n",
      "21d33b1352c9: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "0de849f8e565: Waiting\n",
      "c51f799dca8f: Waiting\n",
      "2bcdf82aed44: Waiting\n",
      "b21e039321ee: Waiting\n",
      "445a2d2462f0: Waiting\n",
      "6e539e6b11c3: Waiting\n",
      "b67f8b8feccd: Waiting\n",
      "7e60813e02c4: Waiting\n",
      "0d66ccba1288: Waiting\n",
      "20b46ade1e43: Waiting\n",
      "21d33b1352c9: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "feea62d2284a: Waiting\n",
      "b935f2592798: Waiting\n",
      "002d32ec2908: Waiting\n",
      "310a7e118b6f: Pushed\n",
      "e296e18ea079: Pushed\n",
      "66cd0085c1ee: Pushed\n",
      "7379bcdcda5f: Pushed\n",
      "100c5dee2eae: Pushed\n",
      "b935f2592798: Pushed\n",
      "0de849f8e565: Pushed\n",
      "c51f799dca8f: Pushed\n",
      "002d32ec2908: Pushed\n",
      "2bcdf82aed44: Pushed\n",
      "b21e039321ee: Pushed\n",
      "7e60813e02c4: Pushed\n",
      "445a2d2462f0: Pushed\n",
      "6e539e6b11c3: Pushed\n",
      "0d66ccba1288: Pushed\n",
      "20b46ade1e43: Pushed\n",
      "af7ed92504ae: Pushed\n",
      "b67f8b8feccd: Pushed\n",
      "21d33b1352c9: Pushed\n",
      "feea62d2284a: Pushed\n",
      "1: digest: sha256:79841ab2a35bec02f393350e4606756f2a7e47b29b5b51a318f35c043bd2be25 size: 4514\n",
      "2023/01/01 21:22:12 Successfully pushed image: 0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f:1\n",
      "2023/01/01 21:22:12 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2023/01/01 21:22:12 Pushing image: 0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f:latest, attempt 1\n",
      "The push refers to repository [0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f]\n",
      "7379bcdcda5f: Preparing\n",
      "66cd0085c1ee: Preparing\n",
      "100c5dee2eae: Preparing\n",
      "e296e18ea079: Preparing\n",
      "310a7e118b6f: Preparing\n",
      "feea62d2284a: Preparing\n",
      "b935f2592798: Preparing\n",
      "002d32ec2908: Preparing\n",
      "0de849f8e565: Preparing\n",
      "c51f799dca8f: Preparing\n",
      "2bcdf82aed44: Preparing\n",
      "b21e039321ee: Preparing\n",
      "445a2d2462f0: Preparing\n",
      "6e539e6b11c3: Preparing\n",
      "b67f8b8feccd: Preparing\n",
      "7e60813e02c4: Preparing\n",
      "0d66ccba1288: Preparing\n",
      "20b46ade1e43: Preparing\n",
      "21d33b1352c9: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "002d32ec2908: Waiting\n",
      "0de849f8e565: Waiting\n",
      "c51f799dca8f: Waiting\n",
      "2bcdf82aed44: Waiting\n",
      "b21e039321ee: Waiting\n",
      "445a2d2462f0: Waiting\n",
      "6e539e6b11c3: Waiting\n",
      "b67f8b8feccd: Waiting\n",
      "7e60813e02c4: Waiting\n",
      "0d66ccba1288: Waiting\n",
      "20b46ade1e43: Waiting\n",
      "21d33b1352c9: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "b935f2592798: Waiting\n",
      "feea62d2284a: Waiting\n",
      "310a7e118b6f: Layer already exists\n",
      "e296e18ea079: Layer already exists\n",
      "66cd0085c1ee: Layer already exists\n",
      "7379bcdcda5f: Layer already exists\n",
      "100c5dee2eae: Layer already exists\n",
      "feea62d2284a: Layer already exists\n",
      "b935f2592798: Layer already exists\n",
      "002d32ec2908: Layer already exists\n",
      "0de849f8e565: Layer already exists\n",
      "2bcdf82aed44: Layer already exists\n",
      "b21e039321ee: Layer already exists\n",
      "445a2d2462f0: Layer already exists\n",
      "c51f799dca8f: Layer already exists\n",
      "6e539e6b11c3: Layer already exists\n",
      "b67f8b8feccd: Layer already exists\n",
      "0d66ccba1288: Layer already exists\n",
      "20b46ade1e43: Layer already exists\n",
      "7e60813e02c4: Layer already exists\n",
      "21d33b1352c9: Layer already exists\n",
      "af7ed92504ae: Layer already exists\n",
      "latest: digest: sha256:79841ab2a35bec02f393350e4606756f2a7e47b29b5b51a318f35c043bd2be25 size: 4514\n",
      "2023/01/01 21:22:13 Successfully pushed image: 0ee9671f71444125a665a1b9cffe5395.azurecr.io/azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f:latest\n",
      "2023/01/01 21:22:13 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 155.547720)\n",
      "2023/01/01 21:22:13 Populating digests for step ID: acb_step_0...\n",
      "2023/01/01 21:22:14 Successfully populated digests for step ID: acb_step_0\n",
      "2023/01/01 21:22:14 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 59.533017)\n",
      "2023/01/01 21:22:14 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.160747)\n",
      "2023/01/01 21:22:14 The following dependencies were found:\n",
      "2023/01/01 21:22:14 \n",
      "- image:\n",
      "    registry: 0ee9671f71444125a665a1b9cffe5395.azurecr.io\n",
      "    repository: azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f\n",
      "    tag: latest\n",
      "    digest: sha256:79841ab2a35bec02f393350e4606756f2a7e47b29b5b51a318f35c043bd2be25\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20221101.v1\n",
      "    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 0ee9671f71444125a665a1b9cffe5395.azurecr.io\n",
      "    repository: azureml/azureml_1c2aabfbb77e8e728d98c56c085c208f\n",
      "    tag: \"1\"\n",
      "    digest: sha256:79841ab2a35bec02f393350e4606756f2a7e47b29b5b51a318f35c043bd2be25\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20221101.v1\n",
      "    digest: sha256:4505a963b2d34a42b5eaef48b8142ca98123d05d3a95eee3fe57551570a70e3b\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: dd2 was successful after 3m40s\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = 'mslearn-diabetes-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print(run.name, ':')\n",
    "    metrics = run.get_metrics()\n",
    "    for metric_name in metrics:\n",
    "        print('\\t',metric_name, \":\", metrics[metric_name])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Publish the pipeline from the run.\n",
    "\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(\"Authentication header ready.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "experiment_name = 'mslearn-diabetes-pipeline'\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
