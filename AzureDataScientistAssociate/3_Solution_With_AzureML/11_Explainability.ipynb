{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Explainability\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "Machine learning models are used to make decisions which should be accurate and explainable to understand what's going on.\n",
    "\n",
    "Model explainers use statistical techniques to calculate _feature importance_. Explainers work by evaluating a test data set of feature cases and the labels the model predicts for them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Globally vs. Locally\n",
    "\n",
    "This assesment can be done globally or locally: the former concerns the relationship between predictions and features, the latter focuses on a single prediction.\n",
    "\n",
    "For the local case, for each label, if we are talking about a classification setting, the feature importance has a value for each label (also for the multi-class classification case). To make a decision, the overall feature importance is computed and the highest will determine the final choice.\n",
    "It's noteworthy that the global result can differ from the local results.\n",
    "\n",
    "For regression models, feature importance will tell you the level of influence each feature has on the predicted scalar label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Development\n",
    "\n",
    "Azure Experiments aren't suited for training explainers but the following method sould be used:\n",
    "- _MimicExplainer_ which tries to explain a model using _a global surrogate model_ characterized by the same architecture of the original one. You should select the most similar architecture to the original one for the surrogate explainer.\n",
    "- _TabularExplainer_ exploits a wrapper around SHAP explainer algorithms, automatically choosing the one that is most appropriate for your model architecture.\n",
    "- _PFIExplainer_ (Permutation Feature Importance) uses shuffle procedures for measuring the impace on predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explain a local model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define an experiment.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "labels = ['not-diabetic', 'diabetic']\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "print('Model trained.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Let's start with a Tabular Explainer.\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "tab_explainer = TabularExplainer(model, X_train, features = features, classes = labels)\n",
    "\n",
    "print(tab_explainer, 'ready!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Global feature importance.\n",
    "\n",
    "global_tab_explanation = tab_explainer.explain_global(X_train)\n",
    "global_tab_feature_importance = global_tab_explanation.get_feature_importance_dict()\n",
    "\n",
    "for feature, importance in global_tab_feature_importance:\n",
    "    print(feature, ':', importance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Local explanation.\n",
    "\n",
    "X_explain = X_test[0:2]\n",
    "predictions = model.predict(X_explain)\n",
    "\n",
    "local_tab_explanation = tab_explainer.explain_local(X_explain)\n",
    "\n",
    "local_tab_features = local_tab_explanation.get_ranked_local_names()\n",
    "local_tab_importance = local_tab_explanation.get_ranked_local_names()\n",
    "\n",
    "for l in range(len(local_tab_features)):\n",
    "    print('Support for', labels[l])\n",
    "    label = local_tab_features[l]\n",
    "    for o in range(len(label)):\n",
    "        print(\"\\tObservation\", o + 1)\n",
    "        feature_list = label[o]\n",
    "        total_support = 0\n",
    "        for f in range(len(feature_list)):\n",
    "            print(\"\\t\\t\", feature_list[f], ':', local_tab_importance[l][o][f])\n",
    "            total_support += local_tab_importance[l][o][f]\n",
    "        print(\"\\t\\t ----------\\n\\t\\t Total:\", total_support, \"Prediction:\", labels[predictions[o]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explain a registered model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Environment\n",
    "from azureml.core import ComputeTarget\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "env = Environment.from_conda_specification('experiment_env', 'environment.yml')\n",
    "compute = ComputeTarget(workspace=ws, name = 'ravazzil-compute')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# After training a model, a TabularExplainer is used to explain the model\n",
    "# and ExplanationClient upload it to the output folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"<string>\\\", line 197, in <module>\\n  File \\\"<string>\\\", line 193, in main\\n  File \\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\", line 261, in run_path\\n    code, fname = _get_code_from_file(run_name, path_name)\\n  File \\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\", line 236, in _get_code_from_file\\n    code = compile(f.read(), fname, 'exec')\\n  File \\\"11_Explainability.py\\\", line 1\\n    %%writefile $experiment_folder/diabetes_training.py\\n    ^\\nSyntaxError: invalid syntax\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"<string>\\\\\\\", line 197, in <module>\\\\n  File \\\\\\\"<string>\\\\\\\", line 193, in main\\\\n  File \\\\\\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\\\\\", line 261, in run_path\\\\n    code, fname = _get_code_from_file(run_name, path_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\\\\\", line 236, in _get_code_from_file\\\\n    code = compile(f.read(), fname, 'exec')\\\\n  File \\\\\\\"11_Explainability.py\\\\\\\", line 1\\\\n    %%writefile $experiment_folder/diabetes_training.py\\\\n    ^\\\\nSyntaxError: invalid syntax\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mActivityFailedException\u001B[0m                   Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17620\\4245583027.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mexp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mExperiment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'explain-exp'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mworkspace\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mws\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mrun\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mexp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubmit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_config\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mrun\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait_for_completion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Anaconda3\\envs\\azure_env\\lib\\site-packages\\azureml\\core\\run.py\u001B[0m in \u001B[0;36mwait_for_completion\u001B[1;34m(self, show_output, wait_post_processing, raise_on_error)\u001B[0m\n\u001B[0;32m    880\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    881\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mraise_on_error\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 882\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0mActivityFailedException\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror_details\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindent\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    883\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    884\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mfinal_details\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mActivityFailedException\u001B[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"<string>\\\", line 197, in <module>\\n  File \\\"<string>\\\", line 193, in main\\n  File \\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\", line 261, in run_path\\n    code, fname = _get_code_from_file(run_name, path_name)\\n  File \\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\", line 236, in _get_code_from_file\\n    code = compile(f.read(), fname, 'exec')\\n  File \\\"11_Explainability.py\\\", line 1\\n    %%writefile $experiment_folder/diabetes_training.py\\n    ^\\nSyntaxError: invalid syntax\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"<string>\\\\\\\", line 197, in <module>\\\\n  File \\\\\\\"<string>\\\\\\\", line 193, in main\\\\n  File \\\\\\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\\\\\", line 261, in run_path\\\\n    code, fname = _get_code_from_file(run_name, path_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_5518ccf8fcac4a509c5f671e21707be5/lib/python3.6/runpy.py\\\\\\\", line 236, in _get_code_from_file\\\\n    code = compile(f.read(), fname, 'exec')\\\\n  File \\\\\\\"11_Explainability.py\\\\\\\", line 1\\\\n    %%writefile $experiment_folder/diabetes_training.py\\\\n    ^\\\\nSyntaxError: invalid syntax\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core import Experiment\n",
    "\n",
    "run_config = ScriptRunConfig(source_directory = './Script',\n",
    "                             script='11_Explainability.py',\n",
    "                             environment=env,\n",
    "                             compute_target=compute\n",
    "                             )\n",
    "exp = Experiment(name = 'explain-exp', workspace = ws)\n",
    "run = exp.submit(run_config)\n",
    "run.wait_for_completion()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Retrieve the results.\n",
    "\n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "client = ExplanationClient.from_run(run)\n",
    "engineered_explanations = client.download_model_explanation()\n",
    "feature_importances = engineered_explanations.get_feature_importance_dict()\n",
    "\n",
    "# Overall feature importance\n",
    "print('Feature\\tImportance')\n",
    "for key, value in feature_importances.items():\n",
    "    print(key, '\\t', value)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
