{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Explainability\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "Machine learning models are used to make decisions which should be accurate and explainable to understand what's going on.\n",
    "\n",
    "Model explainers use statistical techniques to calculate _feature importance_. Explainers work by evaluating a test data set of feature cases and the labels the model predicts for them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Globally vs. Locally\n",
    "\n",
    "This assesment can be done globally or locally: the former concerns the relationship between predictions and features, the latter focuses on a single prediction.\n",
    "\n",
    "For the local case, for each label, if we are talking about a classification setting, the feature importance has a value for each label (also for the multi-class classification case). To make a decision, the overall feature importance is computed and the highest will determine the final choice.\n",
    "It's noteworthy that the global result can differ from the local results.\n",
    "\n",
    "For regression models, feature importance will tell you the level of influence each feature has on the predicted scalar label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Development\n",
    "\n",
    "Azure Experiments aren't suited for training explainers but the following method sould be used:\n",
    "- _MimicExplainer_ which tries to explain a model using _a global surrogate model_ characterized by the same architecture of the original one. You should select the most similar architecture to the original one for the surrogate explainer.\n",
    "- _TabularExplainer_ exploits a wrapper around SHAP explainer algorithms, automatically choosing the one that is most appropriate for your model architecture.\n",
    "- _PFIExplainer_ (Permutation Feature Importance) uses shuffle procedures for measuring the impace on predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
