{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Work with Data in Azure Machine Learning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datastore\n",
    "\n",
    "_Datastores_ are abstractions for cloud data sources. Especially, they encapsulate the information required to connect to data sources.  They encapsulate the information required to connect to data sources.\n",
    "\n",
    "AzureML supports the creation of datastores for multiple kinds of AzureML source, including:\n",
    "- Azure Storage\n",
    "- Azure Data Lake\n",
    "- Azure SQL Database\n",
    "- Azure Databricks file system\n",
    "\n",
    "By default, each workspace contains two datasources, namely a Azure Storage blob and file container."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore\n",
    "\n",
    "ws = Workspace.from_config()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Data Storage: {\n",
      "  \"name\": \"workspaceblobstore\",\n",
      "  \"container_name\": \"azureml-blobstore-b0c040f4-cad9-4180-843c-f18afbed9fe7\",\n",
      "  \"account_name\": \"amlworksstorage59918767d\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# List datastores.\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "for ds_name in ws.datastores:\n",
    "    if ds_name == default_ds.name:\n",
    "        print(f'Default Data Storage: {default_ds}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Retrieve a datastore.\n",
    "blob_store = Datastore.get(ws, datastore_name='workspaceblobstore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Retrieve the default datastore (workspaceblobstore).\n",
    "blob_store = Datastore.get_default_datastore()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the datastore.\n",
    "# ws.set_default_datastore('blob_data')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#blob_ds = Datastore.register_azure_blob_container(workspace = ws,\n",
    "#                                                  datastore_name = 'blob_data',\n",
    "#                                                  container_name = 'data_container')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to data\n",
      "Uploading an estimated of 1 files\n",
      "Uploading Script/data\\diabetes.csv\n",
      "Uploaded Script/data\\diabetes.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": "{\n  \"source\": [\n    \"('workspaceblobstore', '/data')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ]\n}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload a local dataset in the datastorage.\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core import Dataset\n",
    "\n",
    "Dataset.File.upload_directory(src_dir = 'Script/data',\n",
    "                              target = DataPath(default_ds, 'data'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset\n",
    "\n",
    "Dataset are _versioned_ packaged data objects that can be easily consumed in the experiment and pipelines.\n",
    "\n",
    "Datasets are typically based on files in a datastore, though they can also be based on URLs and other sources. The following type of datasets can be created:\n",
    "- _Tabular_: data are read as a table.\n",
    "- _File_: data are stored as a list of files.\n",
    "\n",
    "First, a dataset must be created and then, it should be registered in the workspace to be used in the experiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a dataset object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "    PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n0     1354778            0            171                      80   \n1     1147438            8             92                      93   \n2     1640031            7            115                      47   \n3     1883350            9            103                      78   \n4     1424119            1             85                      59   \n5     1619297            0             82                      92   \n6     1660149            0            133                      47   \n7     1458769            0             67                      87   \n8     1201647            8             80                      95   \n9     1403912            1             72                      31   \n10    1943830            1             88                      86   \n11    1824483            3             94                      96   \n12    1848869            5            114                     101   \n13    1669231            7            110                      82   \n14    1683688            0            148                      58   \n15    1738587            3            109                      77   \n16    1884264            3            106                      64   \n17    1485251            1            156                      53   \n18    1536832            8            117                      39   \n19    1438701            3            102                     100   \n\n    TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n0                 34            23  43.509726          1.213191   21         0  \n1                 47            36  21.240576          0.158365   23         0  \n2                 52            35  41.511523          0.079019   23         0  \n3                 25           304  29.582192          1.282870   43         1  \n4                 27            35  42.604536          0.549542   22         0  \n5                  9           253  19.724160          0.103424   26         0  \n6                 19           227  21.941357          0.174160   21         0  \n7                 43            36  18.277723          0.236165   26         0  \n8                 33            24  26.624929          0.443947   53         1  \n9                 40            42  36.889576          0.103944   26         0  \n10                11            58  43.225041          0.230285   22         0  \n11                31            36  21.294479          0.259020   23         0  \n12                43            70  36.495320          0.079190   38         1  \n13                16            44  36.089293          0.281276   25         0  \n14                11           179  39.192076          0.160829   45         0  \n15                46            61  19.847312          0.204345   21         1  \n16                25            51  29.044573          0.589188   42         1  \n17                15           226  29.786192          0.203824   41         1  \n18                32           164  21.230996          0.089363   25         0  \n19                25           289  42.185720          0.175593   43         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PatientID</th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1354778</td>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1147438</td>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1640031</td>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1883350</td>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1424119</td>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1619297</td>\n      <td>0</td>\n      <td>82</td>\n      <td>92</td>\n      <td>9</td>\n      <td>253</td>\n      <td>19.724160</td>\n      <td>0.103424</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1660149</td>\n      <td>0</td>\n      <td>133</td>\n      <td>47</td>\n      <td>19</td>\n      <td>227</td>\n      <td>21.941357</td>\n      <td>0.174160</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1458769</td>\n      <td>0</td>\n      <td>67</td>\n      <td>87</td>\n      <td>43</td>\n      <td>36</td>\n      <td>18.277723</td>\n      <td>0.236165</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1201647</td>\n      <td>8</td>\n      <td>80</td>\n      <td>95</td>\n      <td>33</td>\n      <td>24</td>\n      <td>26.624929</td>\n      <td>0.443947</td>\n      <td>53</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1403912</td>\n      <td>1</td>\n      <td>72</td>\n      <td>31</td>\n      <td>40</td>\n      <td>42</td>\n      <td>36.889576</td>\n      <td>0.103944</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1943830</td>\n      <td>1</td>\n      <td>88</td>\n      <td>86</td>\n      <td>11</td>\n      <td>58</td>\n      <td>43.225041</td>\n      <td>0.230285</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1824483</td>\n      <td>3</td>\n      <td>94</td>\n      <td>96</td>\n      <td>31</td>\n      <td>36</td>\n      <td>21.294479</td>\n      <td>0.259020</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1848869</td>\n      <td>5</td>\n      <td>114</td>\n      <td>101</td>\n      <td>43</td>\n      <td>70</td>\n      <td>36.495320</td>\n      <td>0.079190</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1669231</td>\n      <td>7</td>\n      <td>110</td>\n      <td>82</td>\n      <td>16</td>\n      <td>44</td>\n      <td>36.089293</td>\n      <td>0.281276</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1683688</td>\n      <td>0</td>\n      <td>148</td>\n      <td>58</td>\n      <td>11</td>\n      <td>179</td>\n      <td>39.192076</td>\n      <td>0.160829</td>\n      <td>45</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1738587</td>\n      <td>3</td>\n      <td>109</td>\n      <td>77</td>\n      <td>46</td>\n      <td>61</td>\n      <td>19.847312</td>\n      <td>0.204345</td>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1884264</td>\n      <td>3</td>\n      <td>106</td>\n      <td>64</td>\n      <td>25</td>\n      <td>51</td>\n      <td>29.044573</td>\n      <td>0.589188</td>\n      <td>42</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1485251</td>\n      <td>1</td>\n      <td>156</td>\n      <td>53</td>\n      <td>15</td>\n      <td>226</td>\n      <td>29.786192</td>\n      <td>0.203824</td>\n      <td>41</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1536832</td>\n      <td>8</td>\n      <td>117</td>\n      <td>39</td>\n      <td>32</td>\n      <td>164</td>\n      <td>21.230996</td>\n      <td>0.089363</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1438701</td>\n      <td>3</td>\n      <td>102</td>\n      <td>100</td>\n      <td>25</td>\n      <td>289</td>\n      <td>42.185720</td>\n      <td>0.175593</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Register a tabular dataset from datastore.\n",
    "blob_ds = ws.get_default_datastore()\n",
    "csv_paths = [(blob_ds, 'data/diabetes.csv')]\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path = csv_paths)\n",
    "\n",
    "tab_ds.take(20).to_pandas_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diabetes.csv\n"
     ]
    }
   ],
   "source": [
    "# Register a file dataset from datastore.\n",
    "\n",
    "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/*.csv'))\n",
    "for file_path in file_ds.to_path():\n",
    "    print(file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Register datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Register the Tabular dataset.\n",
    "\n",
    "try:\n",
    "    tab_ds = tab_ds.register(workspace = ws,\n",
    "                             name = 'diabetes table',\n",
    "                             description = 'Diabetes data',\n",
    "                             tags = {'format': 'CSV'},\n",
    "                             create_new_version = True)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Register the file dataset.\n",
    "\n",
    "try:\n",
    "    file_ds = file_ds.register(workspace = ws,\n",
    "                             name = 'diabetes file data',\n",
    "                             description = 'Diabetes data',\n",
    "                             tags = {'format': 'CSV'},\n",
    "                             create_new_version = True)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t diabetes file data version 1\n",
      "\t diabetes table version 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Versioning is so important for machine learning models because let you define a different version of dataset without removing it: in this case, the experiment which uses that version of data should return some errors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# If you want to use a specific version of data.\n",
    "dataset_v1 = Dataset.get_by_name(ws, 'diabetes table', version = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train a model with table dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'runId': 'mslearn-train-diabetes_1671482266_9449f548',\n 'target': 'my-compute',\n 'status': 'Completed',\n 'startTimeUtc': '2022-12-19T20:37:46.603191Z',\n 'endTimeUtc': '2022-12-19T20:37:48.352495Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  'ContentSnapshotId': '13660cc4-770e-40fd-958a-4c50471328d9',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json',\n  'azureml.git.repository_uri': 'https://github.com/LuciaRavazzi/AzureML.git',\n  'mlflow.source.git.repoURL': 'https://github.com/LuciaRavazzi/AzureML.git',\n  'azureml.git.branch': 'main',\n  'mlflow.source.git.branch': 'main',\n  'azureml.git.commit': '8d87150fc14085920177589fd302d4f345ee8897',\n  'mlflow.source.git.commit': '8d87150fc14085920177589fd302d4f345ee8897',\n  'azureml.git.dirty': 'True'},\n 'inputDatasets': [{'dataset': {'id': '62c31925-6d0a-466c-8d6a-8573666c3b2d'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': '5_Dataset.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--regularization',\n   '0.1',\n   '--input-data',\n   'DatasetConsumptionConfig:training_data'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'my-compute',\n  'dataReferences': {},\n  'data': {'training_data': {'dataLocation': {'dataset': {'id': '62c31925-6d0a-466c-8d6a-8573666c3b2d',\n      'name': 'diabetes table',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Direct',\n    'environmentVariableName': 'training_data',\n    'pathOnCompute': None,\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2022-12-12T20:39:07Z_4fb9d47c',\n   'assetId': 'azureml://locations/francecentral/workspaces/b0c040f4-cad9-4180-843c-f18afbed9fe7/environments/experiment_env/versions/Autosave_2022-12-12T20:39:07Z_4fb9d47c',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'name': 'simple_environment',\n     'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}]},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {},\n 'submittedBy': 'Lucia Ravazzi'}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "env = Environment.from_conda_specification('experiment_env', 'environment.yml')\n",
    "\n",
    "diabetes_ds = ws.datasets.get(\"diabetes table\")\n",
    "\n",
    "# Note that if you use this approach, you still need to include a script\n",
    "# argument for the dataset, even though you don’t actually use it to retrieve the dataset.\n",
    "script_config = ScriptRunConfig(source_directory = 'Script',\n",
    "                                script = '5_Train_Dataset.py',\n",
    "                                environment = env,\n",
    "                                compute_target = 'my-compute',\n",
    "                                arguments = ['--regularization', 0.1,\n",
    "                                             '--input-data', diabetes_ds.as_named_input('training_data')],\n",
    "                                docker_runtime_config=DockerConfiguration(use_docker=True)\n",
    "                                )\n",
    "\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "exp = Experiment(workspace = ws, name = experiment_name)\n",
    "run = exp.submit(config = script_config)\n",
    "run.complete()\n",
    "run.wait_for_completion()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If you want to retrieve the datset trough the ID\n",
    "#script_config = ScriptRunConfig(source_directory = 'Script',\n",
    "#                                script = '5_Train_Dataset.py',\n",
    "#                                environment = env,\n",
    "#                                compute_target = 'my-compute',\n",
    "#                                arguments = ['--regularization', 0.1,\n",
    "#                                             '--input-data', diabetes_ds.as_named_input#('training_data')],\n",
    "#                                docker_runtime_config=DockerConfiguration(use_docker=True)\n",
    "#                                )\n",
    "\n",
    "# In the Script:\n",
    "# from azureml.core import Run, Dataset\n",
    "# parser.add_argument('--ds', type=str, dest='dataset_id')\n",
    "# args = parser.parse_args()\n",
    "# run = Run.get_context()\n",
    "# ws = run.experiment.workspace\n",
    "# dataset = Dataset.get_by_id(ws, id=args.dataset_id)\n",
    "# data = dataset.to_pandas_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train a model from file data\n",
    "\n",
    "In this case, you should use .as_download() or .as_mount() in order to use a temporary location for files. The former download the data, the latter streams the data from the source which is quite convenient when the volume of data is huge."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "{'runId': 'mslearn-train-diabetes_1671483479_77de376a',\n 'target': 'my-compute',\n 'status': 'Completed',\n 'startTimeUtc': '2022-12-19T20:58:02.117808Z',\n 'endTimeUtc': '2022-12-19T20:58:04.030098Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  'ContentSnapshotId': '258542a0-9636-402b-9202-08b2637ba3a3',\n  'azureml.git.repository_uri': 'https://github.com/LuciaRavazzi/AzureML.git',\n  'mlflow.source.git.repoURL': 'https://github.com/LuciaRavazzi/AzureML.git',\n  'azureml.git.branch': 'main',\n  'mlflow.source.git.branch': 'main',\n  'azureml.git.commit': '8d87150fc14085920177589fd302d4f345ee8897',\n  'mlflow.source.git.commit': '8d87150fc14085920177589fd302d4f345ee8897',\n  'azureml.git.dirty': 'True',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [{'dataset': {'id': '007a308b-03d7-45dc-b762-672f073c27db'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_files', 'mechanism': 'Download'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': '6_Train_File_Dataset.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--regularization',\n   '0.1',\n   '--input-data',\n   'DatasetConsumptionConfig:training_files'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'my-compute',\n  'dataReferences': {},\n  'data': {'training_files': {'dataLocation': {'dataset': {'id': '007a308b-03d7-45dc-b762-672f073c27db',\n      'name': 'diabetes file data',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Download',\n    'environmentVariableName': 'training_files',\n    'pathOnCompute': None,\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'experiment_env',\n   'version': 'Autosave_2022-12-12T20:39:07Z_4fb9d47c',\n   'assetId': 'azureml://locations/francecentral/workspaces/b0c040f4-cad9-4180-843c-f18afbed9fe7/environments/experiment_env/versions/Autosave_2022-12-12T20:39:07Z_4fb9d47c',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'name': 'simple_environment',\n     'dependencies': ['python=3.6.2',\n      'scikit-learn',\n      'pandas',\n      'pip',\n      {'pip': ['azureml-defaults', 'azureml-mlflow']}]},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {},\n 'submittedBy': 'Lucia Ravazzi'}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "env = Environment.from_conda_specification('experiment_env', 'environment.yml')\n",
    "\n",
    "diabetes_ds = ws.datasets.get(\"diabetes file data\")\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory = 'Script',\n",
    "                                script = '6_Train_File_Dataset.py',\n",
    "                                environment = env,\n",
    "                                compute_target = 'my-compute',\n",
    "                                arguments = ['--regularization', 0.1,\n",
    "                                             '--input-data', diabetes_ds.as_named_input('training_files').as_download()],\n",
    "                                docker_runtime_config=DockerConfiguration(use_docker=True)\n",
    "                                )\n",
    "\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "exp = Experiment(workspace = ws, name = experiment_name)\n",
    "run = exp.submit(config = script_config)\n",
    "run.complete()\n",
    "run.wait_for_completion()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
